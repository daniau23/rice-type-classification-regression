{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import pickle\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 \n",
      "\n",
      "[[7142, 5.519973094772435, 91.3811065247902, 0.05883361588833924, 9261, 191.824503920258, 0.6521102641145395, 111.35964567974015, 0.3101513175686006, 1.158870259718641, 2], [2815, 43.5782791290656, 78.0291260788307, 0.5172628257649005, 1559, 5.533228691058145, 0.14434602352952652, 296.1557206831996, 0.1924613251155436, 3.0303757586763824, 0], [8752, 39.104321008700495, 10.894641344245137, 0.5938476021217994, 3500, 92.42280135882635, 0.4280282700785848, 132.28066206950646, 0.8129428681518998, 1.0028410441712183, 1], [2020, 74.65997958742521, 31.031365244149946, 0.9101330491621145, 1487, 103.37181716118906, 0.4470735559085611, 413.6092286447162, 0.8381698650664317, 4.988896626409375, 2], [8748, 78.8342252286097, 71.86960814323349, 0.2826827391849861, 718, 5.286103166682921, 0.4111193187453629, 492.57043794013134, 0.9503225191937856, 0.32914312769133425, 1]] \n",
      "\n",
      "[7142, 5.519973094772435, 91.3811065247902, 0.05883361588833924, 9261, 191.824503920258, 0.6521102641145395, 111.35964567974015, 0.3101513175686006, 1.158870259718641, 2] \n",
      "\n",
      "11 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def generate_new_data():\n",
    "    new_data_points = []\n",
    "    \n",
    "    for _ in range(5):\n",
    "        new_data_point = []\n",
    "        \n",
    "        # Generate random values for the features\n",
    "        new_data_point.append(random.randint(0, 10000)) # area\n",
    "        new_data_point.append(random.uniform(0, 200))   # majoraxislength\n",
    "        new_data_point.append(random.uniform(0, 100))   # minoraxislength\n",
    "        new_data_point.append(random.uniform(0, 1))     # eccentricity    \n",
    "        new_data_point.append(random.randint(0, 10000)) # convexarea\n",
    "        new_data_point.append(random.uniform(0, 200))   # equivdiameter\n",
    "        new_data_point.append(random.uniform(0, 1))     # extent\n",
    "        new_data_point.append(random.uniform(0, 500))   # perimeter\n",
    "        new_data_point.append(random.uniform(0, 1))     # roundness\n",
    "        new_data_point.append(random.uniform(0, 5))     # aspectration\n",
    "        new_data_point.append(random.randint(0, 4))     # clusters\n",
    "\n",
    "        \n",
    "        new_data_points.append(new_data_point)\n",
    "    \n",
    "    return new_data_points\n",
    "\n",
    "# Generate 5 new data points\n",
    "new_data = generate_new_data()\n",
    "# The list\n",
    "print(len(new_data),\"\\n\")\n",
    "print(new_data,\"\\n\")\n",
    "\n",
    "# The inner list\n",
    "print(new_data[0],\"\\n\")\n",
    "print(len(new_data[0]),\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pipeline from the file\n",
    "with open('../pipeline/pipeline_classifier.pkl', 'rb') as f:\n",
    "    loaded_pipeline = pickle.load(f)\n",
    "\n",
    "# Load the pipeline from the file\n",
    "with open('../pipeline/pipeline_classifier2.pkl', 'rb') as f:\n",
    "    loaded_pipeline2 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(\"../model/deep_classifier\")\n",
    "model2 = tf.keras.models.load_model(\"../model/deep_classifier2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data taken from class_predictor.ipynb (replace values when ran)\n",
    "new_data = [[6783, 134.38424025738405, 51.87313470141544, 0.21405976093038004, 5642, 8.299512305912792, 0.8973637779065164, 432.31314336510053, 0.08502158418434835, 0.9696327818581052, 0], [5732, 56.59106824094528, 67.19794807821484, 0.7931840814259042, 653, 141.10465999177666, 0.05402723821766464, 232.60784302854864, 0.5752051323023281, 1.4874666389166613, 4], [4906, 116.29686179098609, 89.03377714727696, 0.04036443534194234, 2389, 95.66485536618711, 0.2389558483470109, 95.24464895307094, 0.67460647136312, 0.5152900906380975, 1], [5283, 144.7016795135189, 36.90821944594237, 0.6143751464370153, 8271, 148.69141218570925, 0.9735531139562249, 270.2316416000104, 0.6320263764535171, 4.827186769880548, 4], [9212, 127.1828927212562, 1.4139135475296105, 0.580027340057703, 9464, 81.72230355315978, 0.21461456373284304, 201.97473000715004, 0.9077937464050593, 4.93825134835398, 1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipline: 6\n",
      "Pipline2: 11\n"
     ]
    }
   ],
   "source": [
    "transformed_data = loaded_pipeline.transform(new_data)\n",
    "print(f\"Pipline: {transformed_data.shape[1]}\")\n",
    "\n",
    "transformed_data2 = loaded_pipeline2.transform(new_data).astype(np.float64)\n",
    "print(f\"Pipline2: {transformed_data2.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 182ms/step\n",
      "Model1: [1, 0, 0, 0, 0]\n",
      "1/1 [==============================] - 0s 253ms/step\n",
      "Model2: [1, 0, 0, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "mapper = {0:\"gonen\",1:\"jasmine\"}\n",
    "y_pred_proba  = model.predict(transformed_data)\n",
    "# Convert probabilities to binary predictions\n",
    "y_pred = (y_pred_proba > 0.5).astype(int)\n",
    "\n",
    "predictions = [predictions for sublist in y_pred.tolist() for predictions in sublist]\n",
    "print(f\"Model1: {predictions}\")\n",
    "\n",
    "# model2\n",
    "y_pred_proba2  = model2.predict(transformed_data2)\n",
    "# Convert probabilities to binary predictions\n",
    "y_pred2 = (y_pred_proba2 > 0.5).astype(np.int32) \n",
    "\n",
    "predictions2 = [predictions for sublist in y_pred2.tolist() for predictions in sublist]\n",
    "print(f\"Model2: {predictions2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model1: ['jasmine', 'gonen', 'gonen', 'gonen', 'gonen']\n",
      "Model2: ['jasmine', 'gonen', 'gonen', 'gonen', 'jasmine']\n"
     ]
    }
   ],
   "source": [
    "mapped_predictions = [mapper[value] for value in predictions]\n",
    "print(f\"Model1: {mapped_predictions}\")\n",
    "\n",
    "mapped_predictions2 = [mapper[value] for value in predictions2]\n",
    "print(f\"Model2: {mapped_predictions2}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0d3784fccdc90acbf957f8297e7e306d4c8b14c1a207bd5307d0795df9a8d77b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
